{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSDのforwardを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SSDクラスのfoward処理を実装する\n",
    "\"\"\"\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decode : loc と dbox から bboxを計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SSDの推論時には、順伝搬の最後にクラスDetectを用いる。\n",
    "   Detectクラスの中で使用する関数decodeと関数nm_suppressionを実装\n",
    "\n",
    "　　関数decode:\n",
    "        DBox=(cx_d, cy_d, w_d, h_d)とSSDモデルから求めたオフセット情報loc=(Δcx, Δcy, Δw, Δh)を使用し、\n",
    "        BBoxの座標情報を作成する.\n",
    "\n",
    "        BBoxの情報は、\n",
    "        cx = cx_d * (1 + 0.1 * Δcx)\n",
    "        cy = cy_d * (1 + 0.1 * Δcy)\n",
    "        w  = w_d * exp(0.2 * Δw)\n",
    "        h  = h_d * exp(0.2 * Δh)\n",
    "\n",
    "        さらに、表示形式を(cx, cy, w, h)-> (xmin, ymin, xmax, ymax)に変換する.\n",
    "\"\"\"\n",
    "def decode(loc, dbox_list):\n",
    "    \"\"\"オフセット情報を使い、DBoxをBBoxに変換\n",
    "    \n",
    "    Arguments:\n",
    "        loc {[8732, 4]} -- [SSDモデルで推論するオフセット情報]\n",
    "        dbox_list {[8732, 4]} -- [DBoxの情報]\n",
    "\n",
    "    Return:\n",
    "        bboxes : 8732 x [xmin, ymin, xmax, ymax]\n",
    "    \"\"\"\n",
    "\n",
    "    # DBoxは[cx, cy, width, height]\n",
    "    # locは[Δcx, Δcy, Δw, Δh]\n",
    "    \"\"\"変換式\n",
    "        cx = cx_d * (1 + 0.1 * Δcx)\n",
    "        cy = cy_d * (1 + 0.1 * Δcy)\n",
    "        w  = w_d * exp(0.2 * Δw)\n",
    "        h  = h_d * exp(0.2 * Δh)\n",
    "    \"\"\"\n",
    "    centers = dbox_list[:, :2] + dbox_list[:, :2] * 0.1 * loc[:, :2]\n",
    "    sizes = dbox_list[:, 2:] * torch.exp(loc[:, :2] * 0.2)\n",
    "    bboxes = torch.cat(\n",
    "        (centers, sizes),\n",
    "        dim=1)\n",
    "\n",
    "    # 表示形式を(cx, cy, w, h)-> (xmin, ymin, xmax, ymax)に変換する\n",
    "    bboxes[:, :2] -= bboxes[:, 2:] / 2 # [xmin, ymin] = [cx - w/2, cy - h/2]\n",
    "    bboxes[:, 2:] += bboxes[:, :2]     # [xmax, ymax] = [xmin + w, ymin + h]\n",
    "\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non_maximum_suppressionを実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Maximum-Suppression処理\n",
    "# 同じ物体クラスを指し示す複数のBBoxがある場合に、\n",
    "# 閾値overlap = 0.45以上のBBoxは冗長なBBoxとして排除して、\n",
    "# 残ったBBoxの中で最も確信度Confが高いBBoxを残す\n",
    "def NonMaximum_Suppression(boxes, scores, overlap=0.45, top_k=200):\n",
    "    # bboxes : [確信度0.01を超えたBboxの数, 4] loc情報\n",
    "    # scores : [確信度0.01を超えたBBoxの数]    conf情報\n",
    "\n",
    "\n",
    "    # returnの雛形を作成\n",
    "    count = 0\n",
    "    keep = scores.new(scores.size()).zero_().long()\n",
    "    # keep : torch.Size([確信度を超えたBBoxの数]) 要素は全部0\n",
    "\n",
    "    # BBoxの領域を計算\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    area = torch.mum(x2 - x1, y2 - y1)\n",
    "\n",
    "    # BBoxの被り度合いIoUの計算に使用する変数\n",
    "    tmp_x1 = boxes.new()\n",
    "    tmp_y1 = boxes.new()\n",
    "    tmp_x2 = boxes.new()\n",
    "    tmp_y2 = boxes.new()\n",
    "    tmp_w = boxes.new()\n",
    "    tmp_h = boxes.new()\n",
    "\n",
    "    # scoresを昇順ソート\n",
    "    sorted_scores, idx = scores.sort(dim=0) # 0次元でソート\n",
    "    \n",
    "    # 上位top_k個(200個)のBBoxのindexを取り出す(200個存在しない場合もある)\n",
    "    idx_top_k = idx[-top_k:]\n",
    "\n",
    "    # idx_top_kの要素数が0出ない限りループ\n",
    "    while idx_top_k.numel() > 0:\n",
    "        i = idx_top_k[-1] # 現在のconf最大のindexをiにセット\n",
    "\n",
    "        # keepにconf最大のindexをセット\n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "\n",
    "        # 最後のBBoxになった場合は、break\n",
    "        if idx_top_k.size(0) == 1:\n",
    "            break\n",
    "\n",
    "        # idx_top_kの最後の要素を一つ減らす\n",
    "        idx_top_k = idx_top_k[:-1]\n",
    "\n",
    "        \"\"\"keepに格納したBBoxと被りが大きいBBoxを抽出して消去\n",
    "        \"\"\"\n",
    "        # 1つ要素を減らしたidx_top_kまでのBBoxを,outに指定した変数として作成\n",
    "        torch.index_select(x1, 0, idx_top_k, out=tmp_x1)\n",
    "        torch.index_select(y1, 0, idx_top_k, out=tmp_y1)\n",
    "        torch.index_select(x2, 0, idx_top_k, out=tmp_x2)\n",
    "        torch.index_select(y2, 0, idx_top_k, out=tmp_y2)\n",
    "\n",
    "        # 全てのBBoxに対して、現在のBBox=indexがiとかぶっている値までに設定(clamp)\n",
    "        tmp_x1 = torch.clamp(tmp_x1, min=x1[i])\n",
    "        tmp_y1 = torch.clamp(tmp_y1, min=y1[i])\n",
    "        tmp_x2 = torch.clamp(tmp_x2, max=x2[i])\n",
    "        tmp_y2 = torch.clamp(tmp_y2, max=y2[i])\n",
    "\n",
    "        # wとhのテンソルサイズを1つ減らしたものにする\n",
    "        tmp_w.resize_as_(tmp_x2)\n",
    "        tmp_h.resize_as_(tmp_y2)\n",
    "\n",
    "        # clampした状態でのBBoxの幅と高さを求める\n",
    "        tmp_w = tmp_x2 - tmp_x1\n",
    "        tmp_h = tmp_y2 - tmp_y1\n",
    "        \n",
    "        # 幅や高さが負に成っているものは0にする\n",
    "        tmp_w = torch.clamp(tmp_w, min=0.0)\n",
    "        tmp_h = torch.clamp(tmp_h, min=0.0)\n",
    "\n",
    "        # clampされた状態での面積(かぶっている領域)\n",
    "        inter = tmp_w * tmp_h\n",
    "\n",
    "        # IoU = intersect / Union\n",
    "        rem_areas = torch.index_select(area, 0, idx_top_k) # 各BBoxの元の面積\n",
    "        union = area[i] + (rem_areas - inter)              # union\n",
    "        IoU = inter / union\n",
    "\n",
    "        # IoUがoverlapより小さいidx_top_kのみを残す\n",
    "        idx_top_k = idx_top_k[IoU.le(overlap)] # leは Less than or Equal to\n",
    "\n",
    "    return keep, count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラスDetectを実装 : (loc, conf, dbox)から確信度conf>0.01で、IoU>0.45を満たすオフセットされたアンカーボックス(BBox)を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"クラスDetect\n",
    "    output : \n",
    "        (batch_num, 21, 200, 5)\n",
    "            batch_num : バッチサイズ\n",
    "            21        : クラスラベルの数\n",
    "            200       : 信頼度上位200個のBBox\n",
    "            5         : (conf, xmin, ymin, width, height)\n",
    "            \n",
    "    input :\n",
    "        ※ 8732はスケールを様々に変えたアンカーボックスの数\n",
    "        loc  : 各アンカーボックスのオフセット情報    (batch_num, 8732, 4)\n",
    "        conf : 各アンカーボックスに対するクラスラベル (batch_num, 8732, 21)   \n",
    "        dbox : 各アンカーボックスの位置情報         (8732, 4)\n",
    "\"\"\"\n",
    "class Detect(torch.autograd.Function):\n",
    "    \n",
    "    def __init__(self, conf_thresh=0.01, top_k=200, nms_thresh=0.45):\n",
    "        \n",
    "        # 確信度confを正規化する\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "        # conf_thresh\n",
    "        self.conf_thresh = conf_thresh\n",
    "        \n",
    "        # non-maximum-suppressionで各推定BBoxの上位top_k個を使う\n",
    "        self.top_k = top_k\n",
    "        \n",
    "        # IoUの閾値nms_thresh\n",
    "        self.nms_thresh = nms_thresh\n",
    "        \n",
    "        \n",
    "    def forward(self, loc_data, conf_data, dbox_list):\n",
    "        \"\"\"\n",
    "            クラスラベル数21個に属する上位top_kに入る確信度を持つオフセットを施した\n",
    "            各BBox(decoded_boxes)にnon-maximum-suppressionを適用してBBoxを絞り、\n",
    "            1枚の画像の中で必要なBBoxを得る\n",
    "            \n",
    "            input :\n",
    "                ※ 8732はスケールを様々に変えたアンカーボックスの数\n",
    "                loc  : 各アンカーボックスのオフセット情報    (batch_num, 8732, 4)\n",
    "                conf : 各アンカーボックスに対するクラスラベル (batch_num, 8732, 21)   \n",
    "                dbox : 各アンカーボックスの位置情報         (8732, 4)\n",
    "            \n",
    "            output:\n",
    "                torch.Size([batch_num, 21, 200, 5])\n",
    "        \"\"\"\n",
    "        \n",
    "        num_batch = loc_data.size(0)    # バッチサイズ\n",
    "        num_dbox = loc_data.size(1)     # デフォルトボックス(8732)\n",
    "        num_classes = conf_data.size(2) # クラス数\n",
    "        \n",
    "        # confは正規化\n",
    "        conf_data = self.softmax(conf_data)\n",
    "        \n",
    "        # 出力の型\n",
    "        output = torch.zeros(num_batch, num_classes, self.top_k, 5)\n",
    "        \n",
    "        # conf_data: (batch_num, 8732, num_classes) -> (batch_num, num_classes, 8732)\n",
    "        conf_pred = conf_data.transpose(1, 2)\n",
    "        \n",
    "        \n",
    "        for i in range(num_batch):\n",
    "            \n",
    "            # 1) BBox(8732, 4)を求める\n",
    "            decoded_boxes = decode(loc_data[i], dbox_list)\n",
    "            \n",
    "            # 2) confのコピー(21, 8732)\n",
    "            conf_scores = conf_pred[i].clone()\n",
    "            \n",
    "            # 3) 画像クラス毎のループ(背景クラスのindexである0は計算せず、index=1から)\n",
    "            for cl in range(1, num_classes):\n",
    "                \n",
    "                # 4) conf>0.01に該当するマスク(c_mask)を作成[True, False, False, ...]\n",
    "                # torch.Size([8732])\n",
    "                c_mask = conf_scores[cl].gt(self.conf_thresh)\n",
    "                \n",
    "                # 5) 該当するconfを抽出\n",
    "                scores = conf_scores[cl][c_mask]\n",
    "                \n",
    "                \"\"\"該当するBBoxを抽出\n",
    "                \"\"\"\n",
    "                \n",
    "                # conf_thresh閾値を超えたconfがない場合(socres=[])\n",
    "                # 何もしない\n",
    "                if scores.element() == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # c_maskをdecoded_boxesに適用できるように次元を調整\n",
    "                l_maks = c_mask.unsqueeze(1).as_expand(decoded_boxes)\n",
    "                \n",
    "                # 該当するBBoxを抽出\n",
    "                boxes = decoded_boxes[l_mask].view(-1, 4)\n",
    "                # decoded_boxes[l_mask]で1次元になってしまうので、viewで(閾値を超えたBBox数, 4)サイズに変形\n",
    "                \n",
    "                # Non-Maximum-Suppressionを実行\n",
    "                ids, count = non_maximum_suppression(boxes, scores, self.nm_thresh, self.top_k)\n",
    "                # ids   : confの降順にNon-Maximum Suppressionを通過したindexが格納されている\n",
    "                # count : Non-Maximum Suppressionを通過したBBoxの数\n",
    "                \n",
    "                # outputにNon-Maximum Suppressionを通過した結果を格納\n",
    "                output[i, cl, :count] = torch.cat(\n",
    "                                           (score[idx[:count]].unsqueeze(1), boxes[idx[:count]]),\n",
    "                                           dim = 1)\n",
    "                \n",
    "        return output # (batch_num, classes_num, top_k, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
