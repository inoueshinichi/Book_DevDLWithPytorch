{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSDのNetモデルを構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "#torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    VGG   -> VGG16モデル. source1とsource2を出力\\n    Extra -> source2からsource3, source4, source5, source6を出力\\n    Loc   -> source1 ~ source6 から8732個のDBoxのオフセット情報を出力  : torch.Size([1, 8732, 4])\\n    Conf  -> source1 ~ source6 から8732個のDBoxの確信度情報を出力     : torch.Size([1, 8732, 4])  \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"SSD用ネットワークモデル\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "    VGG   -> VGG16モデル. source1とsource2を出力\n",
    "    Extra -> source2からsource3, source4, source5, source6を出力\n",
    "    Loc   -> source1 ~ source6 から8732個のDBoxのオフセット情報を出力  : torch.Size([1, 8732, 4])\n",
    "    Conf  -> source1 ~ source6 から8732個のDBoxの確信度情報を出力     : torch.Size([1, 8732, 4])  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"改良VGGモジュール\n",
    "    inputs: img_data[n x 300 x 300 x 3]\n",
    "\n",
    "    outputs: conv4_3[n x ○ x ○ x 512]\n",
    "             source2[n x 19 x 19 x 1024]\n",
    "\n",
    "    net:\n",
    "        1) 300 x 300 x 3\n",
    "           Conv2d(kernel_size=3, s=1, p=1, d=1, zero_padding) + ReLU : 300 x 300 x 64\n",
    "           Conv2d(kernel_size=3, s=1, p=1, d=1, zero_padding) + ReLU : 300 x 300 x 64\n",
    "           MaxPool2d(kernel_size=2, s=2, p=0) : 150 x 150 x 128\n",
    "\n",
    "        2) 150 x 150 x 128\n",
    "           Conv2d(kernel_size=3, s=1, p=1, d=1, zero_padding) + ReLU : 150 x 150 x 128\n",
    "           Conv2d(kernel_size=3, s=1, p=1, d=1, zero_padding) + ReLU : 150 x 150 x 128\n",
    "           MaxPool2d(kernel_size=2, s=2, p=0) : 75 x 75 x 256\n",
    "\n",
    "        3) 75 x 75 x 256\n",
    "           Conv2d(kernel_size=3, s=1, p=1, d=1, zero_padding) + ReLU :  75 x 75 x 256\n",
    "           Conv2d(kernel_size=3, s=1, p=1, d=1, zero_padding) + ReLU :  75 x 75 x 256\n",
    "           Conv2d(kernel_size=3, s=1, p=1, d=1, zero_padding) + ReLU :  75 x 75 x 256\n",
    "           Ceiling_MaxPool2d(kernel_size=2, s=2, p=0) : 38 x 38 x 512\n",
    "\n",
    "        4) 38 x 38 x 512\n",
    "           Conv2d(kernel_size=3, s=1, p=1, d=1, zero_padding) + ReLU :  38 x 38 x 512\n",
    "           Conv2d(kernel_size=3, s=1, p=1, d=1, zero_padding) + ReLU :  38 x 38 x 512\n",
    "           Conv2d(kernel_size=3, s=1, p=1, d=1, zero_padding) + ReLU :  38 x 38 x 512 ----> *[L2Norm]* -----> source1\n",
    "           MaxPool2d(kernel_size=2, s=2, p=0) : 19 x 19 x 512\n",
    "\n",
    "        5) 19 x 19 x 512\n",
    "           Conv2d(kernel_size=3, s=1, p=1, d=1, zero_padding) + ReLU :  19 x 19 x 512\n",
    "           Conv2d(kernel_size=3, s=1, p=1, d=1, zero_padding) + ReLU :  19 x 19 x 512\n",
    "           Conv2d(kernel_size=3, s=1, p=1, d=1, zero_padding) + ReLU :  19 x 19 x 512\n",
    "           MaxPool2d(kernel_size=3, s=1, p=1) : 19 x 19 x 1024\n",
    "\n",
    "        6) 19 x 19 x 1024\n",
    "           Conv2d(kernel_size=3, s=1, p=6, d=6, zero_padding) + ReLU :  19 x 19 x 1024 ※ Dilated Convolution\n",
    "           Conv2d(kernel_size=3, s=1, p=0, d=1, zero_padding) + ReLU :  19 x 19 x 1024 ※ Dilated Convolution ----> source2\n",
    "\"\"\"\n",
    "def make_vgg():\n",
    "    # 34層にわたるvggモジュールを作成\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "\n",
    "    # vggモジュールで使用する畳み込み層やMaxPooling層のチャンネル数\n",
    "    cfg = [64, 64, 'M', \n",
    "           128, 128, 'M', \n",
    "           256, 256, 256, 'MC', \n",
    "           512, 512, 512,'M',\n",
    "           512, 512, 512]\n",
    "\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [ nn.MaxPool2d(kernel_size=2, stride=2) ]\n",
    "        elif v == 'MC':\n",
    "            # ceilは出力サイズを、計算結果(float)に対して、切り上げで整数にするモード\n",
    "            # デフォルト(floor)では出力サイズを計算結果(float)に対して、切り下げで整数にするモード\n",
    "            layers += [ nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True) ]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            layers += [ conv2d, nn.ReLU(inplace=True) ]\n",
    "            in_channels = v\n",
    "\n",
    "    # 元のVGG16には\n",
    "    pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "    conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6)\n",
    "    conv7 = nn.Conv2d(1024, 1024, kernel_size=1)\n",
    "    layers += [pool5, conv6, nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)]\n",
    "\n",
    "    return nn.ModuleList(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extraモジュール\n",
    "    inputs : source2[n x 19 x 19 x 1024]\n",
    "\n",
    "    outputs : \n",
    "            source3[n x 10 x 10 x 512]\n",
    "            source4[n x 5 x 5 x 256]\n",
    "            source5[n x 3 x 3 x 512]\n",
    "            source6[n x 1 x 1 x 512]\n",
    "\n",
    "    net: \n",
    "            1) n x 19 x 19 x 1024\n",
    "              Conv2d(kernel_size=1, s=1, p=0, d=1, zero_padding) : 19 x 19 x 256\n",
    "              Conv2d(kernel_size=3, s=2, p=1, d=1, zero_padding) : 10 x 10 x 512 ----> source3\n",
    "\n",
    "            2) n x 10 x 10 x 512\n",
    "              Conv2d(kernel_size=1, s=1, p=0, d=1, zero_padding) : 10 x 10 x 512\n",
    "              Conv2d(kernel_size=3, s=2, p=1, d=1, zero_padding) : 5 x 5 x 256 ----> source4\n",
    "\n",
    "            3) n x 5 x 5 x 256\n",
    "              Conv2d(kernel_size=1, s=1, p=0, d=1, zero_padding) : 5 x 5 x 256\n",
    "              Conv2d(kernel_size=3, s=1, p=0, d=1, zero_padding) : 3 x 3 x 512 ----> source5\n",
    "\n",
    "            4) n x 3 x 3 x 512\n",
    "              Conv2d(kernel_size=1, s=1, p=0, d=1, zero_padding) : 3 x 3 x 512\n",
    "              Conv2d(kernel_size=3, s=1, p=0, d=1, zero_padding) : 1 x 1 x 512 ----> source6\n",
    "\"\"\"\n",
    "def make_extra():\n",
    "    # 8層に渡るextraモジュールを作成\n",
    "    layers = []\n",
    "    in_channels = 1024 # vggの出力のチャネル数\n",
    "\n",
    "    # extraモジュールの畳み込み層のチャネル数を設定する\n",
    "    cfg = [256, 512, 128, 256, 128, 256, 128, 256]\n",
    "\n",
    "    layers += [nn.Conv2d(in_channels, cfg[0], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[0], cfg[1], kernel_size=(3), stride=2, padding=1)]\n",
    "    layers += [nn.Conv2d(cfg[1], cfg[2], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[2], cfg[3], kernel_size=(3), stride=2, padding=1)]\n",
    "    layers += [nn.Conv2d(cfg[3], cfg[4], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[4], cfg[5], kernel_size=(3))]\n",
    "    layers += [nn.Conv2d(cfg[5], cfg[6], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[6], cfg[7], kernel_size=(3))]\n",
    "\n",
    "    return nn.ModuleList(layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Locモジュール\n",
    "    inputs :\n",
    "            source1[n x 38 x 38 x 512]\n",
    "            source2[n x 19 x 19 x 1024]\n",
    "            source3[n x 10 x 10 x 512]\n",
    "            source4[n x 5 x 5 x 256]\n",
    "            source5[n x 3 x 3 x 512]\n",
    "            source6[n x 1 x 1 x 512]\n",
    "\n",
    "    outputs: torch.size([1, 8732, 4])\n",
    "\n",
    "    net:\n",
    "        source1 ----> Conv2d(kernel_size=3, s=1, p=1, zero_padding) : [n x 38 x 38 x 4 x 4] (小正方形, 大正方形, 縦長長方形, 横長長方形) x (Δcx, Δcy, Δwidth, Δheight)\n",
    "        source2 ----> Conv2d(kernel_size=3, s=1, p=1, zero_padding) : [n x ○ x ○ x 6 x 4] (小正方形, 大正方形, 縦長長方形, 横長長方形, 超縦長長方形, 超横長長方形) x (Δcx, Δcy, Δwidth, Δheight)\n",
    "        source3 ----> Conv2d(kernel_size=3, s=1, p=1, zero_padding) : [n x ○ x ○ x 6 x 4] (小正方形, 大正方形, 縦長長方形, 横長長方形, 超縦長長方形, 超横長長方形) x (Δcx, Δcy, Δwidth, Δheight)\n",
    "        source4 ----> Conv2d(kernel_size=3, s=1, p=1, zero_padding) : [n x ○ x ○ x 6 x 4] (小正方形, 大正方形, 縦長長方形, 横長長方形, 超縦長長方形, 超横長長方形) x (Δcx, Δcy, Δwidth, Δheight)\n",
    "        source5 ----> Conv2d(kernel_size=3, s=1, p=1, zero_padding) : [n x ○ x ○ x 4 x 4] (小正方形, 大正方形, 縦長長方形, 横長長方形) x (Δcx, Δcy, Δwidth, Δheight)\n",
    "        source6 ----> Conv2d(kernel_size=3, s=1, p=1, zero_padding) : [n x ○ x ○ x 4 x 4] (小正方形, 大正方形, 縦長長方形, 横長長方形) x (Δcx, Δcy, Δwidth, Δheight)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"Confモジュール\n",
    "    inputs :\n",
    "            source1[n x 38 x 38 x 512]\n",
    "            source2[n x 19 x 19 x 1024]\n",
    "            source3[n x 10 x 10 x 512]\n",
    "            source4[n x 5 x 5 x 256]\n",
    "            source5[n x 3 x 3 x 256]\n",
    "            source6[n x 1 x 1 x 256]\n",
    "\n",
    "    outputs: torch.size([1, 8732, 21])\n",
    "\n",
    "    net:\n",
    "        source1 ----> Conv2d(kernel_size=3, s=1, p=1, zero_padding) : [n x ○ x ○ x 4 x 21] (小正方形, 大正方形, 縦長長方形, 横長長方形) x 21種類のクラスラベル\n",
    "        source2 ----> Conv2d(kernel_size=3, s=1, p=1, zero_padding) : [n x ○ x ○ x 6 x 21] (小正方形, 大正方形, 縦長長方形, 横長長方形, 超縦長長方形, 超横長長方形) x 21種類のクラスラベル\n",
    "        source3 ----> Conv2d(kernel_size=3, s=1, p=1, zero_padding) : [n x ○ x ○ x 6 x 21] (小正方形, 大正方形, 縦長長方形, 横長長方形, 超縦長長方形, 超横長長方形) x 21種類のクラスラベル\n",
    "        source4 ----> Conv2d(kernel_size=3, s=1, p=1, zero_padding) : [n x ○ x ○ x 6 x 21] (小正方形, 大正方形, 縦長長方形, 横長長方形, 超縦長長方形, 超横長長方形) x 21種類のクラスラベル\n",
    "        source5 ----> Conv2d(kernel_size=3, s=1, p=1, zero_padding) : [n x ○ x ○ x 4 x 21] (小正方形, 大正方形, 縦長長方形, 横長長方形) x 21種類のクラスラベル\n",
    "        source6 ----> Conv2d(kernel_size=3, s=1, p=1, zero_padding) : [n x ○ x ○ x 4 x 21] (小正方形, 大正方形, 縦長長方形, 横長長方形) x 21種類のクラスラベル\n",
    "\"\"\"\n",
    "def make_loc_conf(num_classes=21, bbox_aspect_num=[4, 6, 6, 6, 4, 4]):\n",
    "    # デフォルトボックスのオフセットを出力するloc_layers\n",
    "    # デフォルトボックスに対する各クラスの信頼度confidenceを出力するconf_layers\n",
    "\n",
    "    loc_layers = []\n",
    "    conf_layers = []\n",
    "    \n",
    "    # VGGの22層目, conv4_3(source1)に対する畳込み層\n",
    "    loc_layers += [nn.Conv2d(512, bbox_aspect_num[0] * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(512, bbox_aspect_num[0] * num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # VGGの最終層(source2)に対する畳込み層\n",
    "    loc_layers += [nn.Conv2d(1024, bbox_aspect_num[1] * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(1024, bbox_aspect_num[1] * num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # extraの(source3)に対する畳み込み\n",
    "    loc_layers += [nn.Conv2d(512, bbox_aspect_num[2] * 6, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(512, bbox_aspect_num[2] * num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # extraの(source4)に対する畳込み\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[3] * 6, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[3] * num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # extraの(source5)に対する畳込み\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[4] * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[4] * num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # extraの(source6)に対する畳込み\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[5] * 4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[5] * num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    return nn.ModuleList(loc_layers), nn.ModuleList(conf_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"L2ノルム層\n",
    "\"\"\"\n",
    "class L2Norm(nn.Module):\n",
    "    # ConvC4_3からの出力をscale=20のL2normで正規化する\n",
    "    def __init__(self, input_channels = 512, scale=20):\n",
    "        \n",
    "        super(L2Norm, self).__init__()\n",
    "        self.weights = nn.Parameter(torch.Tensor(input_channels))\n",
    "        self.scale = scale      # 係数weightsをscaleで初期化する\n",
    "        self.reset_parameters() # パラメータの初期化\n",
    "        self.eps = 1e-10\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        nn.init.constant_(self.weights, self.scale) # 全てのweightをscale=20で初期化\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        38x38の特徴量に対して、512チャネルに渡って2乗和をのルートを求めた38x38個の値を使用し、\n",
    "        各特徴量を正規化してから係数を掛け算する層\n",
    "        '''\n",
    "        \n",
    "        # normの計算\n",
    "        # normのテンソルサイズはtorch.Size([batch_num, 1, 38, 38])\n",
    "        norm = x.pow(2).sum(dim=1, keepdim=True).sqrt() + self.esp\n",
    "        x = torch.div(x, norm)\n",
    "        \n",
    "        # 係数の次元を調整\n",
    "        # self.weightsのサイズはtorch.Size([512])なので、\n",
    "        # torch.Size([batch_num, 512, 38, 38])まで変形する\n",
    "        weights = self.weights.unsqueeze(0).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        \n",
    "        # 正規化\n",
    "        out = x * weights\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace=True)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace=True)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "  (32): ReLU(inplace=True)\n",
      "  (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (34): ReLU(inplace=True)\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): Conv2d(512, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# VGGモジュール\n",
    "vgg_test = make_vgg()\n",
    "print(vgg_test)\n",
    "\n",
    "# EXTRAモジュール\n",
    "extra_test = make_extra()\n",
    "print(extra_test)\n",
    "\n",
    "# LOC&CONFモジュール\n",
    "loc_test, conf_test = make_loc_conf()\n",
    "print(loc_test)\n",
    "print(conf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSD_default_boxes import DBox\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from SSD_make_SSD_foward import Detect\n",
    "\n",
    "\"\"\"SSDモデルクラスを実装\n",
    "\"\"\"\n",
    "class SSD(nn.Module):\n",
    "\n",
    "    def __init__(self, phase, cfg):\n",
    "        super(SSD, self).__init__()\n",
    "\n",
    "        self.phase = phase # train or interfaceを指定\n",
    "        self.num_classes = cfg['num_classes'] # クラス数=21\n",
    "\n",
    "        # SSDネットワーク\n",
    "        self.vgg = make_vgg()\n",
    "        self.extra = make_extra()\n",
    "        self.L2Norm = L2Norm()\n",
    "        self.loc, self.conf = make_loc_conf(cfg['num_classes'], cfg['bbox_aspect_num'])\n",
    "\n",
    "        # DBox\n",
    "        dbox = DBox(cfg)\n",
    "        self.dbox_list = dbox.make_dbox_list()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            input: (batch_num, 1)の画像\n",
    "\n",
    "            1. source1にL2Normを適用\n",
    "            2. source2を計算\n",
    "            3. source2からsource3~source6を計算\n",
    "            4. source2~source6からlocを計算\n",
    "            5. source2~source6からconfを計算\n",
    "            6. loc, conf, dboxをDetectに通過させ、conf>0.01, IoU>0.45を満たすBBoxを求める\n",
    "\n",
    "            output :\n",
    "                BBox : (batch_num, 21, 200, 5)\n",
    "        \"\"\"\n",
    "\n",
    "        sources = list() # source1~6を格納\n",
    "        loc = list()     # locを格納\n",
    "        conf = list()    # confを格納\n",
    "\n",
    "        # 1) vggのconv4_3まで計算\n",
    "        for k in range(23):\n",
    "            x = self.vgg[k](x)\n",
    "\n",
    "        # 2) conv4_3の出力をL2Normに入力して,source1を作成\n",
    "        source1 = self.L2Norm(x)\n",
    "        sources.append(source1)\n",
    "\n",
    "        # 3) vggを最後まで計算してsource2を作成\n",
    "        for k in range(23, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "        sources.append(x) # source2\n",
    "\n",
    "        # 4) extraのconvとReLUを計算\n",
    "        # source3~source6をsourcesに追加\n",
    "        for k, v in enumerate(self.extras): # k : 0 ~ 7\n",
    "            # 引数なしかinplace=Falseとすると、入力したtensorとは別のtensorが返ってくる。\n",
    "            # inplace=Trueとすると、入力したtensorをそのまま書き換えて返す。 \n",
    "            # 直接書き換えた方がメモリー使用を少なくできる\n",
    "            x = F.relu(v(x), inplace=True)\n",
    "\n",
    "            # 偶数番目はsource*なのでsourcesに追加\n",
    "            if k % 2 == 1:\n",
    "                sources.append(x)\n",
    "\n",
    "        # source1~source6にそれぞれ対応する畳み込みを1回ずつ適用する\n",
    "        # sources, self.loc, self.conf共に要素数6のリスト\n",
    "        for (x, l, c) in zip(sources, self.loc, self.conf):\n",
    "            # permuteは要素の順番を入れ替える\n",
    "            # l(x)とc(x)で畳み込みを実行\n",
    "            # l(x)とc(x)の出力サイズは[batch_num, 4 * アスペクト比の種類数, featureマップの高さ, featureマップの幅]\n",
    "            # sourceによってアスペクト比の種類が異なる([2] or [2, 3])ので4 * アスペクト比の種類数を０次元目に移動させる\n",
    "            # permuteで要素の順番を入れ替える。\n",
    "            # [minibatch_size, featuremap高さ, featuremap幅, f * アスペクト比の種類]\n",
    "            # (注釈)\n",
    "            # torch.contiguos()はメモリ上で要素を連続的に配置し直す命令。\n",
    "            # 後でview関数を使用するが、view関数を行うためには、対象の変数がメモリ上で連続配置されている必要があるから。\n",
    "            loc.append(l(x).permute(0, 2, 3, 1).cotiguous())\n",
    "            conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "\n",
    "        # locとconfの変形(1)\n",
    "        # loc : torch.Size([batch_num, 34928])\n",
    "        # conf: torch.Size([batch_num, 183372])\n",
    "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], dim=1)\n",
    "        conf = torch.cat([o.view(o.size(0), -1) for o in conf], dim=1)\n",
    "\n",
    "        # locとconfの変形(2)\n",
    "        # loc : torch.Size([batch_num, 8732, 4])\n",
    "        # conf: torch.Size([batch_num, 8732, 21])\n",
    "        loc = loc.view(loc.size(0), -1, 4)\n",
    "        conf = conf.view(conf.size(0), -1, self.num_classes)\n",
    "\n",
    "        # 最後に出力\n",
    "        output = (loc, conf, self.dbox_list)\n",
    "\n",
    "        # 推論時と学習時で挙動を変える\n",
    "        if self.phase == 'interface':\n",
    "            # Detectクラスのforwarを実行\n",
    "            # 戻り値のサイズはtorch.Size([batch_num, 21, 200, 5])\n",
    "            return self.detect(output[0], output[1], output[2])\n",
    "        else:\n",
    "            # 学習時\n",
    "            # 戻り値は(loc, conf, dbox_list)のタプル\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
